#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æç°æœ‰çš„NotebookLMçŸ¥è¯†åº“æ–‡ä»¶
"""

import argparse
import os
import re

def analyze_knowledge_base(file_path):
    """
    åˆ†æçŸ¥è¯†åº“æ–‡ä»¶çš„ç»“æ„å’Œå†…å®¹
    
    Args:
        file_path (str): çŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„
    """
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    # è¯»å–æ–‡ä»¶å†…å®¹
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    print(f"ğŸ“Š çŸ¥è¯†åº“æ–‡ä»¶åˆ†ææŠ¥å‘Š: {file_path}")
    print("=" * 60)
    
    # åˆ†ææ–‡ä»¶å¤§å°
    file_size = os.path.getsize(file_path)
    print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {file_size / 1024:.2f} KB")
    
    # åˆ†æå†…å®¹é•¿åº¦
    content_length = len(content)
    print(f"ğŸ“ å†…å®¹é•¿åº¦: {content_length} å­—ç¬¦")
    
    # æå–ç”Ÿæˆæ—¶é—´
    date_match = re.search(r'\*\*ç”Ÿæˆæ—¶é—´\*\*: ([\d-]+)', content)
    if date_match:
        generation_date = date_match.group(1)
        print(f"ğŸ“… ç”Ÿæˆæ—¶é—´: {generation_date}")
    else:
        print("ğŸ“… ç”Ÿæˆæ—¶é—´: æœªæ‰¾åˆ°")
    
    # æå–æ ‡é¢˜
    title_match = re.search(r'# ğŸ“š çŸ¥è¯†åº“ - (.+)', content)
    if title_match:
        title = title_match.group(1)
        print(f"ğŸ“‹ çŸ¥è¯†åº“æ ‡é¢˜: {title}")
    else:
        print("ğŸ“‹ çŸ¥è¯†åº“æ ‡é¢˜: æœªæ‰¾åˆ°")
    
    # åˆ†æç›®å½•ç»“æ„
    table_of_contents_match = re.search(r'## ğŸ“‹ ç›®å½•\n\n(.+?)\n\n---', content, re.DOTALL)
    if table_of_contents_match:
        toc = table_of_contents_match.group(1)
        toc_items = toc.strip().split('\n')
        print(f"ğŸ“‘ ç›®å½•é¡¹æ•°é‡: {len(toc_items)}")
        print("   ç›®å½•å†…å®¹:")
        for item in toc_items:
            print(f"   - {item.strip()}")
    else:
        print("ğŸ“‘ ç›®å½•: æœªæ‰¾åˆ°")
    
    # åˆ†ææ–‡æ¡£å†…å®¹
    docs_match = re.search(r'## ğŸ“„ (.+)\.md\n\n(.+)', content, re.DOTALL)
    if docs_match:
        doc_title = docs_match.group(1)
        doc_content = docs_match.group(2)
        print(f"ğŸ“„ æ–‡æ¡£æ ‡é¢˜: {doc_title}")
        print(f"ğŸ“ æ–‡æ¡£å†…å®¹é•¿åº¦: {len(doc_content)} å­—ç¬¦")
        
        # åˆ†ææ–‡æ¡£ç»“æ„
        sections = re.findall(r'##+ (.+)', doc_content)
        if sections:
            print(f"ğŸ“š æ–‡æ¡£ç« èŠ‚æ•°é‡: {len(sections)}")
            print("   ç« èŠ‚æ ‡é¢˜:")
            for i, section in enumerate(sections[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ªç« èŠ‚
                print(f"   {i+1}. {section.strip()}")
            if len(sections) > 5:
                print(f"   ... ç­‰å…± {len(sections)} ä¸ªç« èŠ‚")
        else:
            print("ğŸ“š æ–‡æ¡£ç« èŠ‚: æœªæ‰¾åˆ°")
    else:
        print("ğŸ“„ æ–‡æ¡£å†…å®¹: æœªæ‰¾åˆ°")
    
    print("=" * 60)
    print("ğŸ’¡ åˆ†æç»“æœæ€»ç»“:")
    print("âœ… æ–‡ä»¶æ ¼å¼ç¬¦åˆNotebookLMè¦æ±‚")
    print("\nğŸ“‹ å»ºè®®æ“ä½œ:")
    print("1. æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦ç¬¦åˆNotebookLMé™åˆ¶")
    print("2. ç¡®ä¿å†…å®¹ç»“æ„æ¸…æ™°ï¼Œä¾¿äºNotebookLMç´¢å¼•")
    print("3. éªŒè¯æ‰€æœ‰ç« èŠ‚æ ‡é¢˜æ ¼å¼æ­£ç¡®")
    print("4. è€ƒè™‘æ·»åŠ æ›´å¤šäº¤å‰å¼•ç”¨ä»¥æé«˜NotebookLMçš„ç†è§£")

def main():
    """
    ä¸»å‡½æ•°ï¼Œå¤„ç†å‘½ä»¤è¡Œå‚æ•°
    """
    parser = argparse.ArgumentParser(description='åˆ†æç°æœ‰çš„NotebookLMçŸ¥è¯†åº“æ–‡ä»¶')
    parser.add_argument('--file', type=str, required=True, help='çŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    analyze_knowledge_base(args.file)

if __name__ == '__main__':
    main()
